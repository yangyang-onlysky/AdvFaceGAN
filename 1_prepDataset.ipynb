{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'utils/align_methods')\n",
    "from utils.align_methods.align import align\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from imageio.v2 import imread, imsave\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "shapes = [(112, 112), (160, 160), (112, 96)]\n",
    "data_dir = \"C:\\yy\\datasets\\lfw\\lfw-deepfunneled\"\n",
    "\n",
    "for name in tqdm(os.listdir(data_dir)):\n",
    "    if 'txt' not in name:\n",
    "        for filename in os.listdir(os.path.join(data_dir, name)):\n",
    "            img = imread(os.path.join(data_dir, name, filename)).astype(np.float32)\n",
    "            img = align(img)[0]\n",
    "            img = img.astype(np.uint8)\n",
    "            for shape in shapes:\n",
    "                out = cv2.resize(img, (shape[1], shape[0]))\n",
    "                output_dir = os.path.join('data', 'lfw-{}x{}'.format(shape[0], shape[1]), name)\n",
    "                if not os.path.exists(output_dir):\n",
    "                    os.makedirs(output_dir)\n",
    "                imsave(os.path.join(output_dir, filename), out)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T03:25:25.214440Z",
     "start_time": "2024-09-26T03:24:59.185210Z"
    }
   },
   "id": "26eaf0c6426862bf",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\compat\\v2_compat.py:101: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n",
      "WARNING:tensorflow:From C:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling reduce_max_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py:206: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From C:\\yy\\source\\Desktop\\读研是一条艰苦的道路\\1. 论文\\做实验\\myCode\\myCode\\4 FrAdv\\AdvFaceGAN\\utils/align_methods\\detect_face.py:213: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 50/5750 [00:10<19:32,  4.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[1], line 17\u001B[0m\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m filename \u001B[38;5;129;01min\u001B[39;00m os\u001B[38;5;241m.\u001B[39mlistdir(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_dir, name)):\n\u001B[0;32m     16\u001B[0m     img \u001B[38;5;241m=\u001B[39m imread(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(data_dir, name, filename))\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39mfloat32)\n\u001B[1;32m---> 17\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[43malign\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     18\u001B[0m     img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mastype(np\u001B[38;5;241m.\u001B[39muint8)\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m shape \u001B[38;5;129;01min\u001B[39;00m shapes:\n",
      "File \u001B[1;32mC:\\yy\\source\\Desktop\\读研是一条艰苦的道路\\1. 论文\\做实验\\myCode\\myCode\\4 FrAdv\\AdvFaceGAN\\utils\\align_methods\\align.py:67\u001B[0m, in \u001B[0;36malign\u001B[1;34m(img, image_size)\u001B[0m\n\u001B[0;32m     65\u001B[0m _bbox \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m     66\u001B[0m _landmark \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 67\u001B[0m bounding_boxes, points \u001B[38;5;241m=\u001B[39m \u001B[43mdetect_face\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdetect_face\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_minsize\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrnet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43monet\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreshold\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfactor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     68\u001B[0m nrof_faces \u001B[38;5;241m=\u001B[39m bounding_boxes\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m]\n\u001B[0;32m     69\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m nrof_faces\u001B[38;5;241m>\u001B[39m\u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[1;32mC:\\yy\\source\\Desktop\\读研是一条艰苦的道路\\1. 论文\\做实验\\myCode\\myCode\\4 FrAdv\\AdvFaceGAN\\utils/align_methods\\detect_face.py:329\u001B[0m, in \u001B[0;36mdetect_face\u001B[1;34m(img, minsize, pnet, rnet, onet, threshold, factor)\u001B[0m\n\u001B[0;32m    327\u001B[0m img_x \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mexpand_dims(im_data, \u001B[38;5;241m0\u001B[39m)\n\u001B[0;32m    328\u001B[0m img_y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtranspose(img_x, (\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m3\u001B[39m))\n\u001B[1;32m--> 329\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[43mpnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg_y\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    330\u001B[0m out0 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtranspose(out[\u001B[38;5;241m0\u001B[39m], (\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m3\u001B[39m))\n\u001B[0;32m    331\u001B[0m out1 \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mtranspose(out[\u001B[38;5;241m1\u001B[39m], (\u001B[38;5;241m0\u001B[39m,\u001B[38;5;241m2\u001B[39m,\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m3\u001B[39m))\n",
      "File \u001B[1;32mC:\\yy\\source\\Desktop\\读研是一条艰苦的道路\\1. 论文\\做实验\\myCode\\myCode\\4 FrAdv\\AdvFaceGAN\\utils/align_methods\\detect_face.py:293\u001B[0m, in \u001B[0;36mcreate_mtcnn.<locals>.<lambda>\u001B[1;34m(img)\u001B[0m\n\u001B[0;32m    290\u001B[0m     onet \u001B[38;5;241m=\u001B[39m ONet({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m'\u001B[39m:data})\n\u001B[0;32m    291\u001B[0m     onet\u001B[38;5;241m.\u001B[39mload(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdet3.npy\u001B[39m\u001B[38;5;124m'\u001B[39m), sess)\n\u001B[1;32m--> 293\u001B[0m pnet_fun \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m img : \u001B[43msess\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpnet/conv4-2/BiasAdd:0\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpnet/prob1:0\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpnet/input:0\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    294\u001B[0m rnet_fun \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m img : sess\u001B[38;5;241m.\u001B[39mrun((\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrnet/conv5-2/conv5-2:0\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrnet/prob1:0\u001B[39m\u001B[38;5;124m'\u001B[39m), feed_dict\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrnet/input:0\u001B[39m\u001B[38;5;124m'\u001B[39m:img})\n\u001B[0;32m    295\u001B[0m onet_fun \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mlambda\u001B[39;00m img : sess\u001B[38;5;241m.\u001B[39mrun((\u001B[38;5;124m'\u001B[39m\u001B[38;5;124monet/conv6-2/conv6-2:0\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124monet/conv6-3/conv6-3:0\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124monet/prob1:0\u001B[39m\u001B[38;5;124m'\u001B[39m), feed_dict\u001B[38;5;241m=\u001B[39m{\u001B[38;5;124m'\u001B[39m\u001B[38;5;124monet/input:0\u001B[39m\u001B[38;5;124m'\u001B[39m:img})\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\client\\session.py:967\u001B[0m, in \u001B[0;36mBaseSession.run\u001B[1;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m    964\u001B[0m run_metadata_ptr \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_NewBuffer() \u001B[38;5;28;01mif\u001B[39;00m run_metadata \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    966\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 967\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_run\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions_ptr\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    968\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mrun_metadata_ptr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    969\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m run_metadata:\n\u001B[0;32m    970\u001B[0m     proto_data \u001B[38;5;241m=\u001B[39m tf_session\u001B[38;5;241m.\u001B[39mTF_GetBuffer(run_metadata_ptr)\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1190\u001B[0m, in \u001B[0;36mBaseSession._run\u001B[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1187\u001B[0m \u001B[38;5;66;03m# We only want to really perform the run if fetches or targets are provided,\u001B[39;00m\n\u001B[0;32m   1188\u001B[0m \u001B[38;5;66;03m# or if the call is a partial run that specifies feeds.\u001B[39;00m\n\u001B[0;32m   1189\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m final_fetches \u001B[38;5;129;01mor\u001B[39;00m final_targets \u001B[38;5;129;01mor\u001B[39;00m (handle \u001B[38;5;129;01mand\u001B[39;00m feed_dict_tensor):\n\u001B[1;32m-> 1190\u001B[0m   results \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_run\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_targets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfinal_fetches\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1191\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mfeed_dict_tensor\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1192\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1193\u001B[0m   results \u001B[38;5;241m=\u001B[39m []\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1368\u001B[0m, in \u001B[0;36mBaseSession._do_run\u001B[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1365\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_tf_sessionprun(handle, feed_dict, fetch_list)\n\u001B[0;32m   1367\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m handle \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m-> 1368\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_do_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_run_fn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeeds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetches\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1369\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1370\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1371\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_do_call(_prun_fn, handle, feeds, fetches)\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1375\u001B[0m, in \u001B[0;36mBaseSession._do_call\u001B[1;34m(self, fn, *args)\u001B[0m\n\u001B[0;32m   1373\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_do_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, fn, \u001B[38;5;241m*\u001B[39margs):\n\u001B[0;32m   1374\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m-> 1375\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1376\u001B[0m   \u001B[38;5;28;01mexcept\u001B[39;00m errors\u001B[38;5;241m.\u001B[39mOpError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1377\u001B[0m     message \u001B[38;5;241m=\u001B[39m compat\u001B[38;5;241m.\u001B[39mas_text(e\u001B[38;5;241m.\u001B[39mmessage)\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1359\u001B[0m, in \u001B[0;36mBaseSession._do_run.<locals>._run_fn\u001B[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[0;32m   1356\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_run_fn\u001B[39m(feed_dict, fetch_list, target_list, options, run_metadata):\n\u001B[0;32m   1357\u001B[0m   \u001B[38;5;66;03m# Ensure any changes to the graph are reflected in the runtime.\u001B[39;00m\n\u001B[0;32m   1358\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_extend_graph()\n\u001B[1;32m-> 1359\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_tf_sessionrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfetch_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1360\u001B[0m \u001B[43m                                  \u001B[49m\u001B[43mtarget_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\frb\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1451\u001B[0m, in \u001B[0;36mBaseSession._call_tf_sessionrun\u001B[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[0;32m   1449\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_call_tf_sessionrun\u001B[39m(\u001B[38;5;28mself\u001B[39m, options, feed_dict, fetch_list, target_list,\n\u001B[0;32m   1450\u001B[0m                         run_metadata):\n\u001B[1;32m-> 1451\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtf_session\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTF_SessionRun_wrapper\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_session\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptions\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeed_dict\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1452\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mfetch_list\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1453\u001B[0m \u001B[43m                                          \u001B[49m\u001B[43mrun_metadata\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/52001 [00:00<?, ?it/s]C:\\Users\\28769\\AppData\\Local\\Temp\\ipykernel_17940\\3792952280.py:13: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n",
      "  img = imread(os.path.join(data_dir, filename)).astype(np.float32)\n",
      "100%|██████████| 52001/52001 [4:07:25<00:00,  3.50it/s]  \n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'utils/align_methods')\n",
    "from utils.align_methods.align import align\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from imageio.v2 import imread, imsave\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "shapes = [(112, 112)]\n",
    "data_dir = r\"D:\\datasets\\ffhq\\ffhq-512×512\"\n",
    "for filename in tqdm(os.listdir(data_dir)):\n",
    "    img = imread(os.path.join(data_dir, filename)).astype(np.float32)\n",
    "    img = align(img)[0]\n",
    "    img = img.astype(np.uint8)\n",
    "    for shape in shapes:\n",
    "        out = cv2.resize(img, (shape[1], shape[0]))\n",
    "        output_dir = os.path.join('data', 'ffhq-{}x{}'.format(shape[0], shape[1]), filename[:-4])\n",
    "        if not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir)\n",
    "        imsave(os.path.join(output_dir, filename), out)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-10T17:53:53.942027Z",
     "start_time": "2024-07-10T13:46:28.304907Z"
    }
   },
   "id": "b155130bd4c232bb",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "计算数据集的真实mean与std"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a4f2e413732e0694",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 207/207 [00:09<00:00, 21.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5366, 0.4246, 0.3550])\n",
      "Std: tensor([0.2340, 0.2030, 0.1931])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_path = r'D:\\datasets\\lfw\\lfw-aligned-112x112'\n",
    "\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 初始化累加器\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "n = 0\n",
    "\n",
    "# 遍历数据集并累加计算\n",
    "for images, _ in tqdm(loader, desc=\"Processing\"):\n",
    "    batch_samples = images.size(0)  # 获取当前批次样本数\n",
    "    images = images.view(batch_samples, images.size(1), -1)  # 展开\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    n += batch_samples\n",
    "\n",
    "mean /= n\n",
    "std /= n\n",
    "\n",
    "print('Mean:', mean)\n",
    "print('Std:', std)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T08:02:10.205484Z",
     "start_time": "2024-06-13T08:01:59.844866Z"
    }
   },
   "id": "9a7a4fdb39b7affb",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing: 100%|██████████| 7119/7119 [08:42<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: tensor([0.5212, 0.4060, 0.3480])\n",
      "Std: tensor([0.2427, 0.2088, 0.1962])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "dataset_path = r'D:/datasets/CASIA-WebFace/casia-aligned-112x112/'\n",
    "\n",
    "# 定义数据转换\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # 将图像转换为张量\n",
    "])\n",
    "\n",
    "# 加载数据集\n",
    "dataset = datasets.ImageFolder(root=dataset_path, transform=transform)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# 初始化累加器\n",
    "mean = torch.zeros(3)\n",
    "std = torch.zeros(3)\n",
    "n = 0\n",
    "\n",
    "# 遍历数据集并累加计算\n",
    "for images, _ in tqdm(loader, desc=\"Processing\"):\n",
    "    batch_samples = images.size(0)  # 获取当前批次样本数\n",
    "    images = images.view(batch_samples, images.size(1), -1)  # 展开\n",
    "    mean += images.mean(2).sum(0)\n",
    "    std += images.std(2).sum(0)\n",
    "    n += batch_samples\n",
    "\n",
    "mean /= n\n",
    "std /= n\n",
    "\n",
    "print('Mean:', mean)\n",
    "print('Std:', std)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-06-13T08:12:01.290639Z",
     "start_time": "2024-06-13T08:03:13.001045Z"
    }
   },
   "id": "56ced5649f9ec37b",
   "execution_count": 19
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "frb",
   "language": "python",
   "display_name": "frb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
