{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-26T04:38:54.420401Z",
     "start_time": "2024-09-26T04:38:36.077486Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "from official_api.facepp import face_compare\n",
    "\n",
    "from AdvFaceGAN import Generator\n",
    "from utils.dataset import Dataset\n",
    "\n",
    "print(\"------------------------加载测试集-------------------------\")\n",
    "test_set = Dataset(\"C:/yy/datasets/lfw/lfw-aligned-112x112/\", \"target\")\n",
    "print(\"-----------------------启动分批队列------------------------\")\n",
    "batch_size = 8\n",
    "test_set.start_batch_queue(\n",
    "    batch_size=batch_size,\n",
    "    batch_format=\"random_samples\",\n",
    "    transforms=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((112,112)),  # 调整图片大小\n",
    "        torchvision.transforms.ToTensor(),  # 图片转为Tensor [0,1]\n",
    "        torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # 归一化\n",
    "    ]),\n",
    "    num_threads=2,\n",
    ")\n",
    "print(\"-----------------------加载生成器------------------------\")\n",
    "fake_generator = Generator(is_target=True).eval().cuda()\n",
    "model_generator_dict = torch.load(r\"C:\\yy\\source\\Desktop\\读研是一条艰苦的道路\\1. 论文\\做实验\\myCode\\myCode\\4 FrAdv\\AdvFaceGAN\\save_dir\\target 3 8白盒 奇怪ssim\\model\\00850_generator.pth\")\n",
    "fake_generator.load_state_dict(model_generator_dict)\n",
    "\n",
    "print(\"-----------------------开始api测试------------------------\")\n",
    "with torch.no_grad():\n",
    "    epoch = 750\n",
    "    after = []\n",
    "    x=0\n",
    "    for i in tqdm(range(0, epoch), total=epoch):\n",
    "        batch = test_set.pop_batch_queue()\n",
    "        source_faces = batch['sources'].cuda()\n",
    "        target_faces = batch['targets'].cuda()\n",
    "        perts, fake_afters = fake_generator.forward(source_faces, target_faces)\n",
    "        for j in range(0, batch_size):\n",
    "            torchvision.utils.save_image([target_faces[j] * 0.5 + 0.5], './test/target.png', nrow=1)\n",
    "            torchvision.utils.save_image([fake_afters[j] * 0.5 + 0.5], './test/fake.png', nrow=1)\n",
    "            res = face_compare(face1_path='./test/target.png', face2_path='./test/fake.png')\n",
    "            if res is None:\n",
    "                x = x+1\n",
    "                torchvision.utils.save_image([source_faces[j] * 0.5 + 0.5], './wrong/facepp/source{}_{}.png'.format(x, batch['sources_name'][j]), nrow=1)\n",
    "                torchvision.utils.save_image([target_faces[j] * 0.5 + 0.5], './wrong/facepp/target{}_{}.png'.format(x, batch['targets_name'][j]), nrow=1)\n",
    "                continue\n",
    "            if res is not None:\n",
    "                after.append(res)\n",
    "    \n",
    "    print(np.mean(after))\n",
    "    after = np.array(after)\n",
    "    print(np.sum(after > 62.327) / len(after))\n",
    "    print(np.sum(after > 69.101) / len(after))\n",
    "    print(np.sum(after > 73.975) / len(after))\n",
    "    \n",
    "\n",
    "'''\n",
    "lfw ：\n",
    "target 3 8白盒 无stloss\n",
    "73.76157870060281\n",
    "0.8590087073007368\n",
    "0.7168452779638312\n",
    "0.5611185532484929\n",
    "\n",
    "target 4 8白盒 无stloss\n",
    "77.8469291931704\n",
    "0.9323736190157349\n",
    "0.8421493136926682\n",
    "0.7216270505523937\n",
    "\n",
    "target 4 8白盒 奇怪ssim 97ssim\n",
    "74.95894014623363\n",
    "0.8831831321203877\n",
    "0.7616051691889134\n",
    "0.6107804795102874\n",
    "\n",
    "celeba_hq \n",
    "target 4 8白盒 无stloss\n",
    "77.13664204545454\n",
    "0.9116161616161617\n",
    "0.7916666666666666\n",
    "0.6698232323232324\n",
    "0.9243806028366088\n",
    "\n",
    "target 4 8白盒 奇怪ssim\n",
    "75.88352572145546\n",
    "0.8795483061480552\n",
    "0.7641154328732748\n",
    "0.6398996235884568\n",
    "0.9430139261484146\n",
    "\n",
    "target 3 8白盒 无stloss\n",
    "72.95020372545729\n",
    "0.8234603121329082\n",
    "0.6746098338647424\n",
    "0.527437489511663\n",
    "0.949701600710551\n",
    "\n",
    "target 3 8白盒 奇怪ssim\n",
    "70.33600285762313\n",
    "0.7599596570852244\n",
    "0.5878298873760296\n",
    "0.4390653891410321\n",
    "0.9642939462661743\n",
    "\n",
    "'''"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------加载测试集-------------------------\n",
      "13233 images of 5749 classes loaded\n",
      "-----------------------启动分批队列------------------------\n",
      "-----------------------加载生成器------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\28769\\AppData\\Local\\Temp\\ipykernel_37308\\1506030890.py:28: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model_generator_dict = torch.load(r\"C:\\yy\\source\\Desktop\\读研是一条艰苦的道路\\1. 论文\\做实验\\myCode\\myCode\\4 FrAdv\\AdvFaceGAN\\save_dir\\target 3 8白盒 奇怪ssim\\model\\00850_generator.pth\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------开始api测试------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/750 [00:00<?, ?it/s]C:\\yy\\installed_software\\Anaconda3\\envs\\AdvFaceGAN\\Lib\\site-packages\\torch\\storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(io.BytesIO(b))\n",
      "  0%|          | 0/750 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: code=401\n",
      "url=https://api-us.faceplusplus.com/facepp/v3/compare\n",
      "b'{\"error_message\":\"AUTHENTICATION_ERROR\"}\\n'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\yy\\\\source\\\\Desktop\\\\读研是一条艰苦的道路\\\\1. 论文\\\\做实验\\\\myCode\\\\myCode\\\\4 FrAdv\\\\AdvFaceGAN\\\\wrong\\\\facepp\\\\source1_Mohammed_Salmane.png'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[2], line 47\u001B[0m\n\u001B[0;32m     45\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m     46\u001B[0m     x \u001B[38;5;241m=\u001B[39m x\u001B[38;5;241m+\u001B[39m\u001B[38;5;241m1\u001B[39m\n\u001B[1;32m---> 47\u001B[0m     \u001B[43mtorchvision\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mutils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave_image\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43msource_faces\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m./wrong/facepp/source\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m_\u001B[39;49m\u001B[38;5;132;43;01m{}\u001B[39;49;00m\u001B[38;5;124;43m.png\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msources_name\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[43mj\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnrow\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     48\u001B[0m     torchvision\u001B[38;5;241m.\u001B[39mutils\u001B[38;5;241m.\u001B[39msave_image([target_faces[j] \u001B[38;5;241m*\u001B[39m \u001B[38;5;241m0.5\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m0.5\u001B[39m], \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m./wrong/facepp/target\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m_\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.png\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(x, batch[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtargets_name\u001B[39m\u001B[38;5;124m'\u001B[39m][j]), nrow\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mcontinue\u001B[39;00m\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\AdvFaceGAN\\Lib\\site-packages\\torch\\utils\\_contextlib.py:116\u001B[0m, in \u001B[0;36mcontext_decorator.<locals>.decorate_context\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    113\u001B[0m \u001B[38;5;129m@functools\u001B[39m\u001B[38;5;241m.\u001B[39mwraps(func)\n\u001B[0;32m    114\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecorate_context\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    115\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m ctx_factory():\n\u001B[1;32m--> 116\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunc\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\AdvFaceGAN\\Lib\\site-packages\\torchvision\\utils.py:151\u001B[0m, in \u001B[0;36msave_image\u001B[1;34m(tensor, fp, format, **kwargs)\u001B[0m\n\u001B[0;32m    149\u001B[0m ndarr \u001B[38;5;241m=\u001B[39m grid\u001B[38;5;241m.\u001B[39mmul(\u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39madd_(\u001B[38;5;241m0.5\u001B[39m)\u001B[38;5;241m.\u001B[39mclamp_(\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m255\u001B[39m)\u001B[38;5;241m.\u001B[39mpermute(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m, torch\u001B[38;5;241m.\u001B[39muint8)\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m    150\u001B[0m im \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(ndarr)\n\u001B[1;32m--> 151\u001B[0m \u001B[43mim\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfp\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mformat\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\yy\\installed_software\\Anaconda3\\envs\\AdvFaceGAN\\Lib\\site-packages\\PIL\\Image.py:2563\u001B[0m, in \u001B[0;36mImage.save\u001B[1;34m(self, fp, format, **params)\u001B[0m\n\u001B[0;32m   2561\u001B[0m         fp \u001B[38;5;241m=\u001B[39m builtins\u001B[38;5;241m.\u001B[39mopen(filename, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mr+b\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   2562\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 2563\u001B[0m         fp \u001B[38;5;241m=\u001B[39m \u001B[43mbuiltins\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilename\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mw+b\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2564\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   2565\u001B[0m     fp \u001B[38;5;241m=\u001B[39m cast(IO[\u001B[38;5;28mbytes\u001B[39m], fp)\n",
      "\u001B[1;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'C:\\\\yy\\\\source\\\\Desktop\\\\读研是一条艰苦的道路\\\\1. 论文\\\\做实验\\\\myCode\\\\myCode\\\\4 FrAdv\\\\AdvFaceGAN\\\\wrong\\\\facepp\\\\source1_Mohammed_Salmane.png'"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------加载测试集-------------------------\n",
      "30000 images of 30000 classes loaded\n",
      "-----------------------启动分批队列------------------------\n",
      "-----------------------加载生成器------------------------\n",
      "-----------------------开始api测试------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 16/750 [04:25<3:32:03, 17.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 34/750 [09:31<3:26:02, 17.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 38/750 [10:36<3:17:18, 16.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 67/750 [18:41<3:10:06, 16.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 90/750 [25:13<3:00:34, 16.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 105/750 [29:30<3:01:51, 16.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 187/750 [53:18<2:52:44, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 221/750 [1:03:32<2:33:08, 17.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 222/750 [1:03:51<2:37:13, 17.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 245/750 [1:10:55<2:35:26, 18.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 271/750 [1:18:57<2:24:20, 18.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 287/750 [1:24:04<2:23:49, 18.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 311/750 [1:31:33<2:20:06, 19.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 329/750 [1:37:16<2:12:31, 18.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 362/750 [1:47:37<2:02:14, 18.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 371/750 [1:50:32<2:05:37, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 373/750 [1:51:06<1:54:44, 18.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n",
      "error: 'confidence'\n",
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 411/750 [2:02:52<1:43:14, 18.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 429/750 [2:08:40<1:46:25, 19.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 441/750 [2:12:41<1:43:51, 20.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 446/750 [2:14:20<1:43:28, 20.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 469/750 [2:21:43<1:27:38, 18.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 472/750 [2:22:41<1:28:55, 19.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 497/750 [2:30:50<1:21:28, 19.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 508/750 [2:34:14<1:15:44, 18.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▊   | 514/750 [2:36:07<1:12:24, 18.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 542/750 [2:45:16<1:08:42, 19.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 545/750 [2:46:14<1:06:44, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 577/750 [2:56:58<1:00:07, 20.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error: 'confidence'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 578/750 [2:57:18<58:47, 20.51s/it]  "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from torchmetrics.functional import structural_similarity_index_measure as ssim\n",
    "from official_api.facepp import face_compare\n",
    "\n",
    "from AdvFaceGAN import Generator\n",
    "from utils.dataset import Dataset\n",
    "\n",
    "print(\"------------------------加载测试集-------------------------\")\n",
    "test_set = Dataset(\"D:/datasets/celeba-hq/celeba_hq-112x112/\", \"target\")\n",
    "print(\"-----------------------启动分批队列------------------------\")\n",
    "batch_size = 8\n",
    "test_set.start_batch_queue(\n",
    "    batch_size=batch_size,\n",
    "    batch_format=\"random_samples\",\n",
    "    transforms=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((112,112)),  # 调整图片大小\n",
    "        torchvision.transforms.ToTensor(),  # 图片转为Tensor [0,1]\n",
    "        torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # 归一化\n",
    "    ]),\n",
    "    num_threads=2,\n",
    ")\n",
    "print(\"-----------------------加载生成器------------------------\")\n",
    "fake_generator = Generator(is_target=True).eval().cuda()\n",
    "model_generator_dict = torch.load(r\"D:\\yy\\source\\Desktop\\读研是一条艰苦的道路\\1. 论文\\做实验\\myCode\\4 FrAdv\\AdvFaceGAN\\save_dir\\target 3 8白盒 正确ssim 无stloss\\model\\00650_generator.pth\")\n",
    "fake_generator.load_state_dict(model_generator_dict)\n",
    "\n",
    "print(\"-----------------------开始api测试------------------------\")\n",
    "with torch.no_grad():\n",
    "    epoch = 750\n",
    "    before = []\n",
    "    after = []\n",
    "    ssim_res = []\n",
    "    x=0\n",
    "    for i in tqdm(range(0, epoch), total=epoch):\n",
    "        batch = test_set.pop_batch_queue()\n",
    "        source_faces = batch['sources'].cuda()\n",
    "        target_faces = batch['targets'].cuda()\n",
    "        perts, fake_afters = fake_generator.forward(source_faces, target_faces)\n",
    "        for j in range(0, batch_size):\n",
    "            torchvision.utils.save_image([target_faces[j] * 0.5 + 0.5], './test/target.png', nrow=1)\n",
    "            torchvision.utils.save_image([fake_afters[j] * 0.5 + 0.5], './test/fake.png', nrow=1)\n",
    "            res = face_compare(face1_path='./test/target.png', face2_path='./test/fake.png')\n",
    "            if res is None:\n",
    "                x = x+1\n",
    "                torchvision.utils.save_image([source_faces[j] * 0.5 + 0.5], './wrong/facepp/source{}_{}.png'.format(x, batch['sources_name'][j]), nrow=1)\n",
    "                torchvision.utils.save_image([target_faces[j] * 0.5 + 0.5], './wrong/facepp/target{}_{}.png'.format(x, batch['targets_name'][j]), nrow=1)\n",
    "                continue\n",
    "            if res is not None:\n",
    "                after.append(res)\n",
    "        ssim_res.append(ssim(source_faces, fake_afters).item())\n",
    "    \n",
    "    print(np.mean(after))\n",
    "    after = np.array(after)\n",
    "    print(np.sum(after > 62.327) / len(after))\n",
    "    print(np.sum(after > 69.101) / len(after))\n",
    "    print(np.sum(after > 73.975) / len(after))\n",
    "    \n",
    "    print(ssim_res)\n",
    "    print(np.mean(ssim_res))\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-25T10:23:35.374977Z"
    }
   },
   "id": "c8e1adc06e710f6d",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# # 算TAR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from official_api.facepp import face_compare\n",
    "\n",
    "from utils.dataset import Dataset\n",
    "\n",
    "print(\"------------------------加载测试集-------------------------\")\n",
    "test_set = Dataset(\"C:/yy/datasets/celeba-hq/celeba_hq-112x112/\", \"target\")\n",
    "print(\"-----------------------启动分批队列------------------------\")\n",
    "batch_size = 8\n",
    "test_set.start_batch_queue(\n",
    "    batch_size=batch_size,\n",
    "    batch_format=\"random_samples\",\n",
    "    transforms=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((112,112)),  # 调整图片大小\n",
    "        torchvision.transforms.ToTensor(),  # 图片转为Tensor [0,1]\n",
    "        torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # 归一化\n",
    "    ]),\n",
    "    num_threads=2,\n",
    "    untarget_same=False\n",
    ")\n",
    "\n",
    "print(\"-----------------------开始api测试------------------------\")\n",
    "with torch.no_grad():\n",
    "    epoch = 200\n",
    "    before = []\n",
    "    x=0\n",
    "    for i in tqdm(range(0, epoch), total=epoch):\n",
    "        batch = test_set.pop_batch_queue()\n",
    "        source_faces = batch['sources'].cuda()\n",
    "        target_faces = batch['targets'].cuda()\n",
    "        for j in range(0, batch_size):\n",
    "            torchvision.utils.save_image([source_faces[j] * 0.5 + 0.5], './test/source.png', nrow=1)\n",
    "            torchvision.utils.save_image([target_faces[j] * 0.5 + 0.5], './test/target.png', nrow=1)\n",
    "            res = face_compare(face1_path='./test/target.png', face2_path='./test/source.png')\n",
    "            if res is None:\n",
    "                x = x+1\n",
    "                torchvision.utils.save_image([source_faces[j] * 0.5 + 0.5], './wrong/facepp/source{}_{}.png'.format(x, batch['sources_name'][j]), nrow=1)\n",
    "                torchvision.utils.save_image([target_faces[j] * 0.5 + 0.5], './wrong/facepp/target{}_{}.png'.format(x, batch['targets_name'][j]), nrow=1)\n",
    "            if res is not None:\n",
    "                before.append(res)\n",
    "    print(np.mean(before))\n",
    "    before = np.array(before)\n",
    "    print(np.sum(after < 62.327) / len(before))\n",
    "    print(np.sum(after < 69.101) / len(before))\n",
    "    print(np.sum(after < 73.975) / len(before))"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "90f6ae0fab80e35e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-27T12:37:43.885213Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 算FAR\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from tqdm import tqdm\n",
    "from official_api.aliyun import face_compare\n",
    "\n",
    "from utils.dataset import Dataset\n",
    "\n",
    "print(\"------------------------加载测试集-------------------------\")\n",
    "test_set = Dataset(\"C:/yy/datasets/celeba-hq/celeba_hq-112x112/\", \"target\")\n",
    "print(\"-----------------------启动分批队列------------------------\")\n",
    "batch_size = 8\n",
    "test_set.start_batch_queue(\n",
    "    batch_size=batch_size,\n",
    "    batch_format=\"random_samples\",\n",
    "    transforms=torchvision.transforms.Compose([\n",
    "        torchvision.transforms.Resize((112,112)),  # 调整图片大小\n",
    "        torchvision.transforms.ToTensor(),  # 图片转为Tensor [0,1]\n",
    "        torchvision.transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),  # 归一化\n",
    "    ]),\n",
    "    num_threads=2,\n",
    "    untarget_same=False\n",
    ")\n",
    "\n",
    "print(\"-----------------------开始api测试------------------------\")\n",
    "with torch.no_grad():\n",
    "    epoch = 200\n",
    "    before = []\n",
    "    x=0\n",
    "    for i in tqdm(range(0, epoch), total=epoch):\n",
    "        batch = test_set.pop_batch_queue()\n",
    "        source_faces = batch['sources'].cuda()\n",
    "        target_faces = batch['targets'].cuda()\n",
    "        for j in range(0, batch_size):\n",
    "            torchvision.utils.save_image([source_faces[j] * 0.5 + 0.5], './test/source.png', nrow=1)\n",
    "            torchvision.utils.save_image([target_faces[j] * 0.5 + 0.5], './test/target.png', nrow=1)\n",
    "            res = face_compare(face1_path='./test/target.png', face2_path='./test/source.png')\n",
    "            if res is None:\n",
    "                x = x+1\n",
    "                torchvision.utils.save_image([source_faces[j] * 0.5 + 0.5], './wrong/facepp/source{}_{}.png'.format(x, batch['sources_name'][j]), nrow=1)\n",
    "                torchvision.utils.save_image([target_faces[j] * 0.5 + 0.5], './wrong/facepp/target{}_{}.png'.format(x, batch['targets_name'][j]), nrow=1)\n",
    "            if res is not None:\n",
    "                before.append(res)\n",
    "    print(np.mean(before))\n",
    "    before = np.array(before)\n",
    "    print(np.sum(after > 62.327) / len(before))\n",
    "    print(np.sum(after > 69.101) / len(before))\n",
    "    print(np.sum(after > 73.975) / len(before))"
   ],
   "id": "72c2a76d4e5a1395",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "3cdaef7e9668d0c0",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "advfacegan",
   "language": "python",
   "display_name": "AdvFaceGAN"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
